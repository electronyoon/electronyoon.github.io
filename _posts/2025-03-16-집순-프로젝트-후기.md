---
layout: post
title: "집순 프로젝트 후기"
category: reviews
last_modified_at: 2025-03-21
---

1. [부동산은 불편하다](#1-부동산은-불편하다)
2. [컨셉](#2-컨셉)
3. [구현](#3-구현)
4. [집순은 어디까지 버틸 수 있을까](#4-집순은-어디까지-버틸-수-있을까)
5. [챌린지: 선택적 리소스 처리](#5-챌린지-선택적-리소스-처리)
6. [챌린지: 포괄적 요청 추적 시스템](#6-챌린지-포괄적-요청-추적-시스템)
7. [챌린지: 지오스페이셜 쿼리 성능 향상](#7-챌린지-지오스페이셜-쿼리-성능-향상)

---

# 1. 부동산은 불편하다

- 저는 네이버 부동산으로 남의 집을 염탐하는 것을 좋아합니다. "저기서는 어떻게 살아볼까" 새로운 삶을 꿈꿔보곤 해요.
- 그런데 그거 아시나요. 내 기호에 딱 맞는 부동산을 찾아주는 서비스는 어디에도 없습니다.
- 네이버 부동산이나 직방, 피터팬 뿐만이 아닙니다. 북미의 zillow, realtor 등도 마찬가지입니다.
<img src="{{ site.baseurl }}/assets/attachments/2025-03-16/Figure 1.png" style="width: 100%; height: auto;">

- 다들 이렇게 말하는 듯합니다. "네가 뭘 원하는 지는 모르겠어, 여기 다 줄테니 알아서 체크박스에 클릭해. 방 2개, 에어컨 1개, 욕조 1개."
- 하지만 이것만으론 부족합니다.
- 누군가는 편의점이 가깝기를, 누군가는 체육시설이 주변에 있기를 바랄 수도 있죠. 누군가는 지하철만 좋아하고 버스는 싫어하지만, 누군가에겐 둘 다 상관 없을 수도 있습니다. 주차장에 물이 잠기는게 무서워 지형상 고지대를 선호할수도 있구요. 상대적으로 제일 낮은 범죄율의 도시에 살고싶어할 수도 있습니다.

집순 프로젝트가 만들어진 이유입니다.
```
다양한 부동산 정보를 조합해 의사 결정을 돕고 싶다.
```

---

# 2. 컨셉

<img src="{{ site.baseurl }}/assets/attachments/2025-03-16/Figure 2.png" style="width: 80%; height: auto;">

- 유저마다 개인화된 매물 점수를 제공하고 싶었습니다.
- 유저에게 여러 가지 `평가 방식`을 제시한 뒤,
- 유저가 스스로 평가 방식을 조합해 나만의 매물 점수를 가지게 하고 싶었습니다.

<br><br>

<img src="{{ site.baseurl }}/assets/attachments/2025-03-16/Figure 3.png" style="width: 80%; height: auto;">

- 그런데 잘 생각해보면, 평가를 하기 위해서는 데이터가 필요합니다.
- 가령 매물의 공원 접근성을 평가하려면, 적어도 전국에 있는 공원의 위치나 면적 등은 가지고 있어야 하죠.
- 그래서 각 평가의 원천 정보를 수집하고 적재하는 `파이프라인`도 만들기로 했습니다.

---

# 3. 구현

- 집순의 데이터 처리 과정은 네 단계로 구성됩니다.

```
1. 매물 수집 → 2. 평가에 필요한 정보 수집 → 3. 점수 계산 → 4. 정규화
```

- 각 단계는 Job으로 구성돼 있습니다. [DataPipelineService](https://github.com/f-lab-edu/zipsoon/blob/main/batch/src/main/java/com/zipsoon/batch/application/pipeline/DataPipelineService.java)가 job을 순서대로 실행합니다. 

<br>

➊ [EstateJob](https://github.com/f-lab-edu/zipsoon/blob/main/batch/src/main/java/com/zipsoon/batch/job/estate/EstateJobConfig.java): 전국 부동산 매물을 찾아 DB에 저장합니다.
- 이를테면 네이버 부동산에서 네이버 매물을 json으로 가져오는 식이죠. → [NaverLandClient](https://github.com/f-lab-edu/zipsoon/blob/main/batch/src/main/java/com/zipsoon/batch/infrastructure/external/naver/NaverLandClient.java)

➋ [SourceJob](https://github.com/f-lab-edu/zipsoon/blob/main/batch/src/main/java/com/zipsoon/batch/job/source/SourceJobConfig.java): 점수를 낼 때 필요한 데이터를 DB에 저장합니다.
- 이를테면 전국 공원 정보가 담긴 csv 파일을 Parks 테이블에 저장하는 식이죠. → [ParkSourceCollector](https://github.com/f-lab-edu/zipsoon/blob/main/batch/src/main/java/com/zipsoon/batch/infrastructure/processor/source/collector/ParkSourceCollector.java)

➌ [ScoreJob](https://github.com/f-lab-edu/zipsoon/blob/main/batch/src/main/java/com/zipsoon/batch/job/score/ScoreJobConfig.java): 특정 척도에 따라 매물별로 점수를 계산합니다.
- 이를테면 공원의 개수, 면적 등을 고려해 11, 20, 19 따위의 점수를 내는 식이죠. → [ParkScoreCalculator](https://github.com/f-lab-edu/zipsoon/blob/main/batch/src/main/java/com/zipsoon/batch/infrastructure/processor/score/calculator/ParkScoreCalculator.java)

➍ [NormalizeJob](https://github.com/f-lab-edu/zipsoon/blob/main/batch/src/main/java/com/zipsoon/batch/job/normalize/NormalizeJobConfig.java): 계산된 점수를 0-10점 사이로 정규화합니다.
- 이를테면 11, 20, 19 따위의 점수를 5, 10, 7점 따위로 변환하는 식이죠. → [LinearScoreNormalizer](https://github.com/f-lab-edu/zipsoon/blob/main/batch/src/main/java/com/zipsoon/batch/infrastructure/processor/normalize/normalizer/LinearScoreNormalizer.java)

<br>

- 각 단계는 수평적 확장에 열려있습니다. 만약 교통이나 편의점 평가 척도를 새로 만들고 싶다면, `TrafficScoreCalculator`나 `ConvstoreScoreCalculator` 등을 만들어 추가하면 됩니다.

---

# 4. 집순은 어디까지 버틸 수 있을까

- 일부 챌린지는 요청을 얼마나 효율적으로 처리하는지를 다룹니다.
- 그러므로 집순 서비스의 운영환경을 가정하고, 부하를 추정해 보겠습니다.

### 피크타임 초당 요청 수(RPS peak)
- RPS는 서버의 처리 성능을 나타내는 대표적인 지표입니다. ***1초에 얼마나 많은 요청을 처리하는지***를 나타냅니다.
  <span class="math">RPS = \frac{Total\ Requests}{Total\ Time\ (seconds)}</span>

- 저는 높은 부하가 걸리는 시간대의 RPS를 추정하고자 했습니다. 다음과 같이 계산해 보겠습니다[^1].
  <span class="math">RPS_{peak} = \frac{Peak\ Requests}{Peak\ Time\ (seconds)} = \frac{DAU \times RPU \times r_{peak}}{t_{peak}}</span>

  - **DAU**: 일 사용자 수
  - **RPU**: 1인당 평균 요청 수
  - **r_peak**: 피크 시간대 요청 비율 (총 요청 중 피크에 발생하는 요청의 비율)
  - **t_peak**: 피크 시간대 길이

- 이제 각 요소를 추정해 보겠습니다.

### i) DAU
- 집순은 신생 서비스이므로, ***DAU는 10만***으로 가정합니다[^2].


### ii) RPU
- 한 유저가 ***평균 30회정도를 요청***한다고 가정합니다[^3].


### iii) r_peak
- ***피크 시간대 요청 비율은 0.1(10%)***로 가정합니다[^4].
- 10%는 다소 낮아보일 수 있으나, 최종 RPS를 보수적으로 책정할 예정이기 때문에 상쇄가 가능합니다.

### iv) t_peak
- ***피크 시간대 길이(초)는 7,200초(2시간)***으로 가정합니다[^4].

### v) 결론

<span class="math">RPS_{peak} = \frac{100,000 \times 30 \times 0.1}{7,200} = \frac{300,000}{7,200} \approx 41.67</span>

- 집순은 **최대 초당 약 42개의 요청**을 처리할 수 있어야 합니다.
- 여유롭게 설계하기 위해 **목표 RPS는 50**으로 설정하겠습니다.

---

# 5. 챌린지: 선택적 리소스 처리

### i) 문제
- ETL 과정에서 매번 모든 데이터 소스(공원, 지하철역 등)를 재처리해야 했습니다.
- 소스 데이터 개수가 늘어날수록 배치 작업 시간이 선형적으로 증가하는 문제가 있습니다.

### ii) 해결
- 데이터 소스의 [변경을 감지](https://github.com/f-lab-edu/zipsoon/blob/main/batch/src/main/java/com/zipsoon/batch/infrastructure/util/BatchJobUtils.java#L59)하도록 개선했습니다.
- 파일과 batch 메타데이터로 변경된 데이터 소스만 확인해 적재합니다.

### iii) 성과

<div class="chart-container">
  <canvas id="timeImprovementChart"></canvas>
</div>

<script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function() {
  // 테스트 결과 데이터
  const testResults = [
    {resourceCount: 2, timeImprovement: 1.29, memoryImprovement: 1.28, cpuImprovement: 1.10},
    {resourceCount: 4, timeImprovement: 2.12, memoryImprovement: 1.09, cpuImprovement: 0.97},
    {resourceCount: 6, timeImprovement: 2.74, memoryImprovement: 0.62, cpuImprovement: 0.94},
    {resourceCount: 8, timeImprovement: 3.82, memoryImprovement: 1.37, cpuImprovement: 1.19},
    {resourceCount: 10, timeImprovement: 4.44, memoryImprovement: 0.84, cpuImprovement: 0.98},
  ];

  // 리소스 개수별 차트 데이터 준비
  const resourceCounts = testResults.map(r => r.resourceCount);
  const timeImprovementData = testResults.map(r => r.timeImprovement);
  
  // 시간 개선 차트
  new Chart(document.getElementById('timeImprovementChart'), {
    type: 'line',
    data: {
      labels: resourceCounts,
      datasets: [{
        label: '처리 시간 개선',
        data: timeImprovementData,
        borderColor: '#36a2eb',
        backgroundColor: 'rgba(54, 162, 235, 0.2)',
        tension: 0.1
      }]
    },
    options: {
      scales: {
        y: {
          title: {
            display: true,
            text: '시간 개선 (배수)'
          },
          suggestedMin: 1
        },
        x: {
          title: {
            display: true,
            text: '리소스 개수'
          }
        }
      }
    }
  });
});
</script>

<style>
table {
  width: 100%; 
  border-collapse: collapse; 
  margin: 20px 0;
}
table, th, td {
  border: 1px solid #ddd;
}
th, td {
  padding: 4px; 
  text-align: right;
}
th {
  background-color: #f2f2f2;
}
</style>

<table>
  <tr>
    <th>리소스 개수</th>
    <th>전체 처리 시간(ms)</th>
    <th>선택적 처리 시간(ms)</th>
    <th>시간 개선</th>
    <th>메모리 개선</th>
    <th>CPU 개선</th>
  </tr>
  <tr>
    <td>2</td>
    <td>100325</td>
    <td>77813</td>
    <td>1.29배</td>
    <td>1.28배</td>
    <td>1.10배</td>
  </tr>
  <tr>
    <td>4</td>
    <td>158378</td>
    <td>74690</td>
    <td>2.12배</td>
    <td>1.09배</td>
    <td>0.97배</td>
  </tr>
  <tr>
    <td>6</td>
    <td>206643</td>
    <td>75470</td>
    <td>2.74배</td>
    <td>0.62배</td>
    <td>0.94배</td>
  </tr>
  <tr>
    <td>8</td>
    <td>276535</td>
    <td>72399</td>
    <td>3.82배</td>
    <td>1.37배</td>
    <td>1.19배</td>
  </tr>
  <tr>
    <td>10</td>
    <td>351809</td>
    <td>79250</td>
    <td>4.44배</td>
    <td>0.84배</td>
    <td>0.98배</td>
  </tr>
</table>

- **처리 효율성**: 10개 데이터 소스 환경에서 처리 시간이 최대 4.4배 단축되었습니다.
- **리소스 최적화**: 불필요한 데이터베이스 트랜잭션과 I/O 작업이 줄어들 것으로 기대할 수 있습니다.

### iv) 한계
- 파일 시뮬레이션으로 테스트했기 때문에, 스프링 환경에서의 정확한 성능 비교가 필요합니다.
- 현재는 파일 수정 시간 기반의 단순 변경 감지 방식이지만, 대규모 데이터 세트에서는 증분 처리 방식이 더 효율적일 수 있습니다.
- 더 다양한 데이터 종류의 감지와 정밀한 변경 감지, 장애 복구 기능이 필요합니다.

---

# 6. 챌린지: 포괄적 요청 추적 시스템

### i) 문제
- 로그 크기가 늘어날수록 텍스트 기반 검색은 선형적으로 느려집니다.
- 서비스가 확장되며 분리된다면, 사용자 요청과 로그가 분산되기에 문제 추적이 어려워집니다.

### ii) 해결
- 분산 환경에서의 요청 추적을 위해 [RequestID 필터](https://github.com/f-lab-edu/zipsoon/blob/main/api/src/main/java/com/zipsoon/api/infrastructure/logging/filter/RequestIdFilter.java)를 구현했습니다.
- 모든 요청에 UUID 기반의 RequestID를 발급하여 MDC에 저장하고, 응답 헤더에도 포함합니다.

### iii) 성과

<div class="chart-container">
  <canvas id="searchTimeChart"></canvas>
</div>

<script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function() {
  // 테스트 결과 데이터
  const searchResults = [
    {logSize: 3600, bruteForceTime: 0.26, requestIdTime: 0.00, timeSaved: 0.26},
    {logSize: 36000, bruteForceTime: 0.74, requestIdTime: 0.00, timeSaved: 0.74},
    {logSize: 360000, bruteForceTime: 8.33, requestIdTime: 0.00, timeSaved: 8.33},
    {logSize: 3600000, bruteForceTime: 72.82, requestIdTime: 0.00, timeSaved: 72.82},
    {logSize: 3600000, bruteForceTime: 1530.19, requestIdTime: 0.00, timeSaved: 1530.19}
  ];

  // 검색 시간 차트
  const logSizes = searchResults.map(r => r.logSize);
  const bruteForceTimeData = searchResults.map(r => r.bruteForceTime);
  const requestIdTimeData = searchResults.map(r => r.requestIdTime);
  
  new Chart(document.getElementById('searchTimeChart'), {
    type: 'line',
    data: {
      labels: logSizes.map(size => size.toLocaleString()),
      datasets: [{
        label: '전체 텍스트 검색 (O(n))',
        data: bruteForceTimeData,
        borderColor: 'rgba(255, 99, 132, 1)',
        backgroundColor: 'rgba(255, 99, 132, 0.2)',
        tension: 0.1
      },
      {
        label: 'RequestID 검색 (O(1))',
        data: requestIdTimeData,
        borderColor: 'rgba(54, 162, 235, 1)',
        backgroundColor: 'rgba(54, 162, 235, 0.2)',
        tension: 0.1
      }]
    },
    options: {
      scales: {
        y: {
          title: {
            display: true,
            text: '검색 시간 (밀리초)'
          },
          beginAtZero: true
        },
        x: {
          title: {
            display: true,
            text: '로그 크기'
          }
        }
      }
    }
  });
});
</script>

<style>
table {
  width: 100%; 
  border-collapse: collapse; 
  margin: 20px 0;
}
table, th, td {
  border: 1px solid #ddd;
}
th, td {
  padding: 4px; 
  text-align: right;
}
th {
  background-color: #f2f2f2;
}
</style>

<table>
  <tr>
    <th>로그 크기</th>
    <th>전체 텍스트 검색 (ms)</th>
    <th>RequestID 검색 (ms)</th>
    <th>절약 시간 (ms)</th>
  </tr>
  <tr>
    <td>3,000</td>
    <td>0.26</td>
    <td>0.00</td>
    <td>0.26</td>
  </tr>
  <tr>
    <td>30,000</td>
    <td>0.74</td>
    <td>0.00</td>
    <td>0.74</td>
  </tr>
  <tr>
    <td>300,000</td>
    <td>8.33</td>
    <td>0.00</td>
    <td>8.33</td>
  </tr>
  <tr>
    <td>3,000,000</td>
    <td>72.82</td>
    <td>0.00</td>
    <td>72.82</td>
  </tr>
  <tr>
    <td>30,000,000</td>
    <td>1530.19</td>
    <td>0.00</td>
    <td>1530.19</td>
  </tr>
</table>

- 다양한 로그 크기를 대상으로 [성능 테스트](https://github.com/f-lab-edu/zipsoon/blob/main/api/src/test/java/com/zipsoon/api/performance/RequestIdPerformanceTest.java)를 수행했습니다.
- **시간 효율성**: 3,000만줄의 로그[^5]에서 단위 검색에 평균 **1530.19ms(약 1.5초)** 절약됩니다.
- **확장성**: 로그가 지수적으로 증가하더라도 동일한 검색 속도를 유지하며, requestId 기반의 모니터링 툴을 연동할 수도 있습니다.

### iv) 한계
- 실제 운영 환경에서는 테스트 환경보다 더 복잡한 로그 패턴과 구조가 발생할 수 있습니다.
- ELK 스택, Datadog 등과 통합하면 더 효율적으로 운영할 수 있습니다. 다만 분산 시스템에서의 지원은 미비합니다.

---

# 7. 챌린지: 지오스페이셜 쿼리 성능 향상

(작성중)


---

# References

[^1]: 피크 요청이 평균 요청보다 얼마나 높은지 비율을 알 수 있다면, 피크 요청 수를 구할 수 있습니다.<span class="math">피크\ 요청\ 수 = ➊전체\ 요청\ 수 \times ➋총\ 요청\ 중\ 피크에\ 발생하는\ 요청의\ 비율</span>➊은 DAU(일일 사용자 수)와 RPU(일인당 평균 요청 수)를 활용합니다. 잘 알려진 지표를 활용하면, 다른 기업의 수치를 참고할 수 있기 때문입니다. 따라서 전체 요청 수 = DAU * RPU입니다.<br>➋는 단순 휴리스틱을 활용합니다. 후술하겠지만 서비스별 피크 요청의 비율을 일반화하기 어렵기 때문입니다.

[^2]: 호갱노노, 직방의 2020년 안드로이드 DAU는 각각 [30만, 25만](https://www.bloter.net/news/articleView.html?idxno=34155)입니다. 2024년 총 DAU는 각각 [53만, 34만](https://adure.net/uploads/adure/1741232115_%EC%A7%81%EB%B0%A9_%ED%98%B8%EA%B0%B1%EB%85%B8%EB%85%B8_%ED%86%B5%ED%95%A9_%EA%B4%91%EA%B3%A0%EC%83%81%ED%92%88_%EC%86%8C%EA%B0%9C%EC%84%9C_v2.5.pdf)입니다. 이에 근거해 직방의 DAU를 30만 정도로 추산했습니다.

[^3]: <div>집순의 엔드포인트 수와 유즈케이스를 고려했습니다.<table>
    <thead>
        <tr>
            <th>카테고리</th>
            <th>엔드포인트</th>
            <th>요청 횟수/세션</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td rowspan="4">매물 관련</td>
            <td>GET /estates/map (지도 로딩 및 이동)</td>
            <td>10-15회</td>
        </tr>
        <tr>
            <td>GET /estates/{id} (매물 상세 조회)</td>
            <td>5-8회</td>
        </tr>
        <tr>
            <td>POST /estates/{id}/favorite (찜하기)</td>
            <td>1-2회</td>
        </tr>
        <tr>
            <td>DELETE /estates/{id}/favorite (찜 해제)</td>
            <td>1-2회</td>
        </tr>
        <tr>
            <td rowspan="2">점수 유형</td>
            <td>GET /score-types (점수 유형 조회)</td>
            <td>1-2회</td>
        </tr>
        <tr>
            <td>POST/DELETE /score-types/{id} (활성/비활성)</td>
            <td>1-2회</td>
        </tr>
        <tr>
            <td>사용자</td>
            <td>GET /users/me/favorites (찜 목록 조회)</td>
            <td>1-2회</td>
        </tr>
        <tr>
            <th colspan="2">총 요청 수/세션</th>
            <th><i>20-30회</i></th>
        </tr>
    </tbody></table></div>

[^4]: <div><span>프롭테크 서비스의 시간-요일-계절별 트래픽 패턴은 알려진 바가 없습니다. 다만 이커머스의 경우, 시간대별 구매 패턴이 잘 알려져 있습니다. <a href="https://www.donga.com/news/Economy/article/all/20211220/110867797/1">한 조사</a>에 따르면 오전 10시와 12시에 가장 많은 구매가 일어납니다.</span><table>
        <thead>
            <tr>
                <th>시간대</th>
                <th>구매 수</th>
                <th>퍼센트(%)</th>
            </tr>
        </thead>
        <tbody>
            <tr><td>...</td><td>...</td><td>...</td></tr>
            <tr><td><b><i>10</i></b></td><td><b><i>56</i></b></td><td><b><i>6.67</i></b></td></tr>
            <tr><td>11</td><td>53</td><td>6.32</td></tr>
            <tr><td><b><i>12</i></b></td><td><b><i>56</i></b></td><td><b><i>6.67</i></b></td></tr>
            <tr><td>...</td><td>...</td><td>...</td></tr>
        </tbody>
    </table>간편한 계산을 위해 구매 트래픽을 조회 트래픽으로 단순 변환했습니다. 어떤 서비스들은 피크 시간대에 20-30%의 부하를 겪는다고 조사했으나, 근거가 명확치 않아 제외합니다.</div>

[^5]: <div>3,000만줄은 1일 추정치입니다. 앞서 DAU를 10만명, RPU를 30회/일로 가정했으므로 <span class="math">일\ 평균\ 총\ API\ 요청\ 수 \approx 10만명 \times 30회 = 300만\ 요청/일</span> 각 요청이 평균 10줄의 로그를 생산한다고 가정하면 <span class="math">일\ 평균\ 로그\ 수 = 300만\ 요청/일 \times 10줄 = 3,000만줄</span> 각 요청에서 생성되는 로그의 양은 다음과 같이 가정했습니다.<table>
    <thead>
        <tr>
            <th>카테고리</th>
            <th>로그 유형</th>
            <th>발생량/API 요청</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td rowspan="3">API 요청당 평균 로그</td>
            <td>API 입출력 로그</td>
            <td>2개</td>
        </tr>
        <tr>
            <td>서비스 레이어 로그</td>
            <td>3-5개</td>
        </tr>
        <tr>
            <td>데이터베이스 조회 로그</td>
            <td>2-3개</td>
        </tr>
        <tr>
            <th colspan="2">총 로그 발생량/API 요청</th>
            <th><i>7개-10개</i></th>
        </tr>
    </tbody></table></div>